{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "b1e2d709-cbf6-4d06-b451-4d975aa517e0",
   "metadata": {},
   "source": [
    "# 本节大纲\n",
    "\n",
    "1. 对话机器人的产品设计, 10分钟\n",
    "2. 大语言模型的使用, 30分钟\n",
    "3. 提示词工程，20分钟\n",
    "4. 开发环境讲解，10分钟\n",
    "5. 工程化代码讲解，35分钟\n",
    "6. 答疑和总结，15分钟"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0554d80a-0dd4-4af2-85a3-1936ac4bf9b4",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bf5ebc70-a976-4b33-bf47-0d0b6b2e415f",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# 这里是依赖库，运行代码前需要先安装\n",
    "!pip install openai pandas tiktoken"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "636a28c2-4be9-49cf-901c-ef858a013ae3",
   "metadata": {},
   "source": [
    "### 如果不用现在的语言模型去做对话会是如何"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "22991687-4d39-4fb3-8602-682fdc58da7a",
   "metadata": {},
   "source": [
    "#### 在最早期的对话系统"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "df504df3-00e1-496f-9efb-60b0853f90a4",
   "metadata": {},
   "outputs": [],
   "source": [
    "def AssistantResponse(user_message):\n",
    "    if user_message in [\"你好\", \"Hello\", \"Bonjour\"]:\n",
    "        return \"欢迎您!\"\n",
    "    elif user_message in [\"你是谁\", \"你叫什么名字\"]:\n",
    "        return \"我是机器人小墨\"\n",
    "    else:\n",
    "        return \"不好意思，我没能理解您的问题\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "1fb4c8ab-e7a2-4806-afd2-8c8cd4a4c12d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "User: 你好\n",
      "Assistant: 欢迎您!\n"
     ]
    }
   ],
   "source": [
    "user_message = \"你好\"\n",
    "print(f'User: {user_message}\\nAssistant: {AssistantResponse(user_message)}')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "811aac1a-2185-45ac-b2ee-ee01b065f713",
   "metadata": {},
   "source": [
    "#### 中间还经历过各种不同技术驱动的系统，例如最经典的 RASA ... "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a893507b-e37f-4589-8007-493fdfbf3637",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 意图识别，技能，填槽，动作"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bbc54488-30a3-4190-a6c9-10d084f16de5",
   "metadata": {},
   "source": [
    "#### 现在，有了大模型的加持，一切都不同了..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "630cabf6-6780-4f6a-9c36-1c791aff690c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "墨问西东是一家专注于提供企业级软件开发和咨询服务的公司。我们为企业提供定制的软件解决方案，帮助企业提高运营效率、降低成本、提升竞争力。\n"
     ]
    }
   ],
   "source": [
    "import openai \n",
    "# openai.api_key = 'Raplace to your API Key' \n",
    "\n",
    "prompt = [\"问题：介绍一下墨问西东是什么类型的公司\\n回答：\"]\n",
    "response = openai.Completion.create(engine=\"text-davinci-002\", prompt=prompt, temperature=0, max_tokens=1024)\n",
    "print(response['choices'][0]['text'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8fb4a231-8097-4d1c-8e1b-45b3a6903a7a",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7c03b895-acad-4c28-9d56-0e565ce9856a",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d8ccf824-f9ab-440b-bd25-e75eb25e45d4",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e9018a2a-32af-4129-9d6d-fd966ac7a26f",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "0ff40005-372b-4ccb-a573-3ac5d834b76d",
   "metadata": {},
   "source": [
    "### 小墨技术全景图"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "47c82e13-5fcc-4ee1-bdfd-d62fb28c6ec9",
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": ""
    },
    "tags": []
   },
   "source": [
    "![Stack](./resource/images/Stack.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d422a143-d3e4-45fe-b42d-5f0a9050dea8",
   "metadata": {},
   "source": [
    "### 小墨关键流程图"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2d7ae5a3-c77a-42c2-848f-77b66260a493",
   "metadata": {},
   "source": [
    "![Schedule](./resource/images/Schedule.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d916c984-12f4-41ee-9906-708a6b7084b7",
   "metadata": {},
   "source": [
    "### 小墨 v0.1 介绍"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "161e144e-03b7-44e6-a4ab-e8ffbcf25477",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 幻觉的存在导致回复的不是我们想要的\n",
    "# 小墨对话机器人应运而生，开始打造 v0.1 版本"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7bd8874c-59fe-44ab-8f61-368a8cc5b98e",
   "metadata": {},
   "source": [
    "![v0.1](./resource/images/v0.1.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e5e3b6eb-7e27-460b-862f-17e8ee20c687",
   "metadata": {},
   "source": [
    "#### 要造一个小墨机器人需要些什么\n",
    "1. 得封装下服务来调用下大语言模型吧\n",
    "2. 需要了解下大语言模型如何调用吧\n",
    "3. 需要有一个前端来给用户操作吧\n",
    "4. 需要知道用户使用的好不好吧\n",
    "5. ..."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c2ac16b6-bcbd-4ddb-b003-950b48a8488b",
   "metadata": {},
   "source": [
    "#### 总而言之，先做一个 POC 来验证下是可行性"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "47f5177a-7a68-4384-888b-82cc4416ef62",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2fc0b426-5380-40a6-a15d-34dc91c77214",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "29f9b781-ca6b-4f9a-b68e-29b762cf1226",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "443e18d3-3905-4c10-acc8-495da64085e5",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "37a788ac-105f-4f39-8a97-4d779659f582",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "afdb5d5b-40e7-4772-ac6a-1e99a4348be8",
   "metadata": {},
   "source": [
    "### LLM 是一个关键，了解下 OpenAI"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a4f08d3b-207a-4db2-9ae8-a36126eeed09",
   "metadata": {},
   "outputs": [],
   "source": [
    "# OpenAI Model\n",
    "# https://platform.openai.com/docs/models/overview"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "357a0175-ee94-4872-ada9-510042a1d3bc",
   "metadata": {},
   "outputs": [],
   "source": [
    "# OpenAI Price\n",
    "# https://openai.com/pricing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "68217676-d8ce-4a45-a947-5ffc6738ad3f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# OpenAI API Rate Limit\n",
    "# https://platform.openai.com/docs/guides/rate-limits"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5322ff57-77dd-4be7-a5b8-41608ec3f689",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 如果遇到：OpenAI‘s services are not available in your country\n",
    "# window.localStorage.removeItem(Object.keys(window.localStorage).find(i=>i.startsWith('@@auth0spajs')))\n",
    "# 复制这段 JavaScript 代码，然后浏览器 F12 进入调试模式，在 Console 对话框粘贴并执行"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "3a04472b-800c-4b56-be1d-62280fe8b29f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>object</th>\n",
       "      <th>id</th>\n",
       "      <th>ready</th>\n",
       "      <th>owner</th>\n",
       "      <th>permissions</th>\n",
       "      <th>created</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>engine</td>\n",
       "      <td>gpt-4-0314</td>\n",
       "      <td>True</td>\n",
       "      <td>openai</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>engine</td>\n",
       "      <td>curie-search-query</td>\n",
       "      <td>True</td>\n",
       "      <td>openai-dev</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>engine</td>\n",
       "      <td>babbage-search-document</td>\n",
       "      <td>True</td>\n",
       "      <td>openai-dev</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>engine</td>\n",
       "      <td>text-search-babbage-doc-001</td>\n",
       "      <td>True</td>\n",
       "      <td>openai-dev</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>engine</td>\n",
       "      <td>babbage</td>\n",
       "      <td>True</td>\n",
       "      <td>openai</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>engine</td>\n",
       "      <td>text-babbage-001</td>\n",
       "      <td>True</td>\n",
       "      <td>openai</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>engine</td>\n",
       "      <td>text-similarity-davinci-001</td>\n",
       "      <td>True</td>\n",
       "      <td>openai-dev</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>engine</td>\n",
       "      <td>davinci</td>\n",
       "      <td>True</td>\n",
       "      <td>openai</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>engine</td>\n",
       "      <td>davinci-similarity</td>\n",
       "      <td>True</td>\n",
       "      <td>openai-dev</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>engine</td>\n",
       "      <td>code-davinci-edit-001</td>\n",
       "      <td>True</td>\n",
       "      <td>openai</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>engine</td>\n",
       "      <td>curie-similarity</td>\n",
       "      <td>True</td>\n",
       "      <td>openai-dev</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>engine</td>\n",
       "      <td>code-search-babbage-code-001</td>\n",
       "      <td>True</td>\n",
       "      <td>openai-dev</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>engine</td>\n",
       "      <td>curie-instruct-beta</td>\n",
       "      <td>True</td>\n",
       "      <td>openai</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>engine</td>\n",
       "      <td>text-search-ada-doc-001</td>\n",
       "      <td>True</td>\n",
       "      <td>openai-dev</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>engine</td>\n",
       "      <td>davinci-instruct-beta</td>\n",
       "      <td>True</td>\n",
       "      <td>openai</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>engine</td>\n",
       "      <td>text-search-davinci-doc-001</td>\n",
       "      <td>True</td>\n",
       "      <td>openai-dev</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>engine</td>\n",
       "      <td>text-curie-001</td>\n",
       "      <td>True</td>\n",
       "      <td>openai</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>engine</td>\n",
       "      <td>davinci-search-query</td>\n",
       "      <td>True</td>\n",
       "      <td>openai-dev</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>engine</td>\n",
       "      <td>text-similarity-curie-001</td>\n",
       "      <td>True</td>\n",
       "      <td>openai-dev</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>engine</td>\n",
       "      <td>text-davinci-001</td>\n",
       "      <td>True</td>\n",
       "      <td>openai</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>engine</td>\n",
       "      <td>text-search-davinci-query-001</td>\n",
       "      <td>True</td>\n",
       "      <td>openai-dev</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>engine</td>\n",
       "      <td>text-davinci-003</td>\n",
       "      <td>True</td>\n",
       "      <td>openai-internal</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>engine</td>\n",
       "      <td>ada-search-document</td>\n",
       "      <td>True</td>\n",
       "      <td>openai-dev</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>engine</td>\n",
       "      <td>ada-code-search-code</td>\n",
       "      <td>True</td>\n",
       "      <td>openai-dev</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>engine</td>\n",
       "      <td>babbage-002</td>\n",
       "      <td>True</td>\n",
       "      <td>system</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>engine</td>\n",
       "      <td>whisper-1</td>\n",
       "      <td>True</td>\n",
       "      <td>openai-internal</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>engine</td>\n",
       "      <td>gpt-4-0613</td>\n",
       "      <td>True</td>\n",
       "      <td>openai</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>engine</td>\n",
       "      <td>gpt-4</td>\n",
       "      <td>True</td>\n",
       "      <td>openai</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>engine</td>\n",
       "      <td>davinci-002</td>\n",
       "      <td>True</td>\n",
       "      <td>system</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29</th>\n",
       "      <td>engine</td>\n",
       "      <td>davinci-search-document</td>\n",
       "      <td>True</td>\n",
       "      <td>openai-dev</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>30</th>\n",
       "      <td>engine</td>\n",
       "      <td>curie-search-document</td>\n",
       "      <td>True</td>\n",
       "      <td>openai-dev</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>31</th>\n",
       "      <td>engine</td>\n",
       "      <td>babbage-code-search-text</td>\n",
       "      <td>True</td>\n",
       "      <td>openai-dev</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>32</th>\n",
       "      <td>engine</td>\n",
       "      <td>babbage-code-search-code</td>\n",
       "      <td>True</td>\n",
       "      <td>openai-dev</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>33</th>\n",
       "      <td>engine</td>\n",
       "      <td>babbage-search-query</td>\n",
       "      <td>True</td>\n",
       "      <td>openai-dev</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>34</th>\n",
       "      <td>engine</td>\n",
       "      <td>text-search-ada-query-001</td>\n",
       "      <td>True</td>\n",
       "      <td>openai-dev</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>35</th>\n",
       "      <td>engine</td>\n",
       "      <td>code-search-ada-text-001</td>\n",
       "      <td>True</td>\n",
       "      <td>openai-dev</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>36</th>\n",
       "      <td>engine</td>\n",
       "      <td>gpt-3.5-turbo-instruct-0914</td>\n",
       "      <td>True</td>\n",
       "      <td>system</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>37</th>\n",
       "      <td>engine</td>\n",
       "      <td>gpt-3.5-turbo-instruct</td>\n",
       "      <td>True</td>\n",
       "      <td>system</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>38</th>\n",
       "      <td>engine</td>\n",
       "      <td>ada-search-query</td>\n",
       "      <td>True</td>\n",
       "      <td>openai-dev</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>39</th>\n",
       "      <td>engine</td>\n",
       "      <td>ada-code-search-text</td>\n",
       "      <td>True</td>\n",
       "      <td>openai-dev</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>40</th>\n",
       "      <td>engine</td>\n",
       "      <td>text-search-curie-query-001</td>\n",
       "      <td>True</td>\n",
       "      <td>openai-dev</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>41</th>\n",
       "      <td>engine</td>\n",
       "      <td>text-davinci-002</td>\n",
       "      <td>True</td>\n",
       "      <td>openai</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>42</th>\n",
       "      <td>engine</td>\n",
       "      <td>code-search-babbage-text-001</td>\n",
       "      <td>True</td>\n",
       "      <td>openai-dev</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>43</th>\n",
       "      <td>engine</td>\n",
       "      <td>text-embedding-ada-002</td>\n",
       "      <td>True</td>\n",
       "      <td>openai-internal</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>44</th>\n",
       "      <td>engine</td>\n",
       "      <td>text-davinci-edit-001</td>\n",
       "      <td>True</td>\n",
       "      <td>openai</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>45</th>\n",
       "      <td>engine</td>\n",
       "      <td>ada</td>\n",
       "      <td>True</td>\n",
       "      <td>openai</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>46</th>\n",
       "      <td>engine</td>\n",
       "      <td>text-ada-001</td>\n",
       "      <td>True</td>\n",
       "      <td>openai</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>47</th>\n",
       "      <td>engine</td>\n",
       "      <td>ada-similarity</td>\n",
       "      <td>True</td>\n",
       "      <td>openai-dev</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>48</th>\n",
       "      <td>engine</td>\n",
       "      <td>code-search-ada-code-001</td>\n",
       "      <td>True</td>\n",
       "      <td>openai-dev</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>49</th>\n",
       "      <td>engine</td>\n",
       "      <td>text-similarity-babbage-001</td>\n",
       "      <td>True</td>\n",
       "      <td>openai-dev</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50</th>\n",
       "      <td>engine</td>\n",
       "      <td>text-similarity-ada-001</td>\n",
       "      <td>True</td>\n",
       "      <td>openai-dev</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>51</th>\n",
       "      <td>engine</td>\n",
       "      <td>gpt-3.5-turbo-0301</td>\n",
       "      <td>True</td>\n",
       "      <td>openai</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>52</th>\n",
       "      <td>engine</td>\n",
       "      <td>curie</td>\n",
       "      <td>True</td>\n",
       "      <td>openai</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>53</th>\n",
       "      <td>engine</td>\n",
       "      <td>babbage-similarity</td>\n",
       "      <td>True</td>\n",
       "      <td>openai-dev</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>54</th>\n",
       "      <td>engine</td>\n",
       "      <td>gpt-3.5-turbo-16k</td>\n",
       "      <td>True</td>\n",
       "      <td>openai-internal</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>55</th>\n",
       "      <td>engine</td>\n",
       "      <td>gpt-3.5-turbo</td>\n",
       "      <td>True</td>\n",
       "      <td>openai</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>56</th>\n",
       "      <td>engine</td>\n",
       "      <td>text-search-babbage-query-001</td>\n",
       "      <td>True</td>\n",
       "      <td>openai-dev</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>57</th>\n",
       "      <td>engine</td>\n",
       "      <td>gpt-3.5-turbo-0613</td>\n",
       "      <td>True</td>\n",
       "      <td>openai</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>58</th>\n",
       "      <td>engine</td>\n",
       "      <td>text-search-curie-doc-001</td>\n",
       "      <td>True</td>\n",
       "      <td>openai-dev</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>59</th>\n",
       "      <td>engine</td>\n",
       "      <td>gpt-3.5-turbo-16k-0613</td>\n",
       "      <td>True</td>\n",
       "      <td>openai</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    object                             id  ready            owner permissions  \\\n",
       "0   engine                     gpt-4-0314   True           openai        None   \n",
       "1   engine             curie-search-query   True       openai-dev        None   \n",
       "2   engine        babbage-search-document   True       openai-dev        None   \n",
       "3   engine    text-search-babbage-doc-001   True       openai-dev        None   \n",
       "4   engine                        babbage   True           openai        None   \n",
       "5   engine               text-babbage-001   True           openai        None   \n",
       "6   engine    text-similarity-davinci-001   True       openai-dev        None   \n",
       "7   engine                        davinci   True           openai        None   \n",
       "8   engine             davinci-similarity   True       openai-dev        None   \n",
       "9   engine          code-davinci-edit-001   True           openai        None   \n",
       "10  engine               curie-similarity   True       openai-dev        None   \n",
       "11  engine   code-search-babbage-code-001   True       openai-dev        None   \n",
       "12  engine            curie-instruct-beta   True           openai        None   \n",
       "13  engine        text-search-ada-doc-001   True       openai-dev        None   \n",
       "14  engine          davinci-instruct-beta   True           openai        None   \n",
       "15  engine    text-search-davinci-doc-001   True       openai-dev        None   \n",
       "16  engine                 text-curie-001   True           openai        None   \n",
       "17  engine           davinci-search-query   True       openai-dev        None   \n",
       "18  engine      text-similarity-curie-001   True       openai-dev        None   \n",
       "19  engine               text-davinci-001   True           openai        None   \n",
       "20  engine  text-search-davinci-query-001   True       openai-dev        None   \n",
       "21  engine               text-davinci-003   True  openai-internal        None   \n",
       "22  engine            ada-search-document   True       openai-dev        None   \n",
       "23  engine           ada-code-search-code   True       openai-dev        None   \n",
       "24  engine                    babbage-002   True           system        None   \n",
       "25  engine                      whisper-1   True  openai-internal        None   \n",
       "26  engine                     gpt-4-0613   True           openai        None   \n",
       "27  engine                          gpt-4   True           openai        None   \n",
       "28  engine                    davinci-002   True           system        None   \n",
       "29  engine        davinci-search-document   True       openai-dev        None   \n",
       "30  engine          curie-search-document   True       openai-dev        None   \n",
       "31  engine       babbage-code-search-text   True       openai-dev        None   \n",
       "32  engine       babbage-code-search-code   True       openai-dev        None   \n",
       "33  engine           babbage-search-query   True       openai-dev        None   \n",
       "34  engine      text-search-ada-query-001   True       openai-dev        None   \n",
       "35  engine       code-search-ada-text-001   True       openai-dev        None   \n",
       "36  engine    gpt-3.5-turbo-instruct-0914   True           system        None   \n",
       "37  engine         gpt-3.5-turbo-instruct   True           system        None   \n",
       "38  engine               ada-search-query   True       openai-dev        None   \n",
       "39  engine           ada-code-search-text   True       openai-dev        None   \n",
       "40  engine    text-search-curie-query-001   True       openai-dev        None   \n",
       "41  engine               text-davinci-002   True           openai        None   \n",
       "42  engine   code-search-babbage-text-001   True       openai-dev        None   \n",
       "43  engine         text-embedding-ada-002   True  openai-internal        None   \n",
       "44  engine          text-davinci-edit-001   True           openai        None   \n",
       "45  engine                            ada   True           openai        None   \n",
       "46  engine                   text-ada-001   True           openai        None   \n",
       "47  engine                 ada-similarity   True       openai-dev        None   \n",
       "48  engine       code-search-ada-code-001   True       openai-dev        None   \n",
       "49  engine    text-similarity-babbage-001   True       openai-dev        None   \n",
       "50  engine        text-similarity-ada-001   True       openai-dev        None   \n",
       "51  engine             gpt-3.5-turbo-0301   True           openai        None   \n",
       "52  engine                          curie   True           openai        None   \n",
       "53  engine             babbage-similarity   True       openai-dev        None   \n",
       "54  engine              gpt-3.5-turbo-16k   True  openai-internal        None   \n",
       "55  engine                  gpt-3.5-turbo   True           openai        None   \n",
       "56  engine  text-search-babbage-query-001   True       openai-dev        None   \n",
       "57  engine             gpt-3.5-turbo-0613   True           openai        None   \n",
       "58  engine      text-search-curie-doc-001   True       openai-dev        None   \n",
       "59  engine         gpt-3.5-turbo-16k-0613   True           openai        None   \n",
       "\n",
       "   created  \n",
       "0     None  \n",
       "1     None  \n",
       "2     None  \n",
       "3     None  \n",
       "4     None  \n",
       "5     None  \n",
       "6     None  \n",
       "7     None  \n",
       "8     None  \n",
       "9     None  \n",
       "10    None  \n",
       "11    None  \n",
       "12    None  \n",
       "13    None  \n",
       "14    None  \n",
       "15    None  \n",
       "16    None  \n",
       "17    None  \n",
       "18    None  \n",
       "19    None  \n",
       "20    None  \n",
       "21    None  \n",
       "22    None  \n",
       "23    None  \n",
       "24    None  \n",
       "25    None  \n",
       "26    None  \n",
       "27    None  \n",
       "28    None  \n",
       "29    None  \n",
       "30    None  \n",
       "31    None  \n",
       "32    None  \n",
       "33    None  \n",
       "34    None  \n",
       "35    None  \n",
       "36    None  \n",
       "37    None  \n",
       "38    None  \n",
       "39    None  \n",
       "40    None  \n",
       "41    None  \n",
       "42    None  \n",
       "43    None  \n",
       "44    None  \n",
       "45    None  \n",
       "46    None  \n",
       "47    None  \n",
       "48    None  \n",
       "49    None  \n",
       "50    None  \n",
       "51    None  \n",
       "52    None  \n",
       "53    None  \n",
       "54    None  \n",
       "55    None  \n",
       "56    None  \n",
       "57    None  \n",
       "58    None  \n",
       "59    None  "
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 查看 OpenAI 提供了什么模型可以使用\n",
    "# 请注意这节课，我们只会用到 Language Model\n",
    "\n",
    "import pandas as pd\n",
    "\n",
    "pd.DataFrame(openai.Engine.list()['data'])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ed29469f-728b-44d6-82c6-a2561ca82e77",
   "metadata": {},
   "source": [
    "#### 写点代码小试牛刀"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "474b1625-79e3-47ad-89d8-00ff8bd01c36",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 原生 OpenAI 客户端 SDK， 记得替换下 OpenAI 的 API Key\n",
    "import openai \n",
    "# openai.api_key = 'Raplace to your API Key' "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "e5f299e4-06eb-4a53-bdc7-853e4a15899c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Completion API\n",
    "# 自然语言生成接口，用于补全等任务，自由风格\n",
    "\n",
    "prompt = [\"Can you tell me who are you\"]\n",
    "\n",
    "response = openai.Completion.create(engine=\"text-davinci-002\", prompt=prompt, temperature=0.1, max_tokens=1024)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "db7e3fee-ca5c-4c49-9a86-1dbac97bcb71",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<OpenAIObject text_completion id=cmpl-81D8SESEacOx1sImHoowAlmgEhuDq at 0x7f45fd052e70> JSON: {\n",
       "  \"warning\": \"This model version is deprecated. Migrate before January 4, 2024 to avoid disruption of service. Learn more https://platform.openai.com/docs/deprecations\",\n",
       "  \"id\": \"cmpl-81D8SESEacOx1sImHoowAlmgEhuDq\",\n",
       "  \"object\": \"text_completion\",\n",
       "  \"created\": 1695299512,\n",
       "  \"model\": \"text-davinci-002\",\n",
       "  \"choices\": [\n",
       "    {\n",
       "      \"text\": \"?\\n\\nI am a 20-year-old student at the University of Utah in the United States.\",\n",
       "      \"index\": 0,\n",
       "      \"logprobs\": null,\n",
       "      \"finish_reason\": \"stop\"\n",
       "    }\n",
       "  ],\n",
       "  \"usage\": {\n",
       "    \"prompt_tokens\": 7,\n",
       "    \"completion_tokens\": 22,\n",
       "    \"total_tokens\": 29\n",
       "  }\n",
       "}"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "response"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "9bf1726e-da3f-459c-b05e-0ed12b293747",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'?\\n\\nI am a 20-year-old student at the University of Utah in the United States.'"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "response['choices'][0]['text']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "cb4278a4-d716-4bff-afd1-9076146eb5b8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Chat API\n",
    "# 对话接口，专门为聊天场景而设计，格式严谨\n",
    "\n",
    "response = openai.ChatCompletion.create(\n",
    "  model=\"gpt-3.5-turbo-0613\",\n",
    "  messages=[\n",
    "        {\"role\": \"system\", \"content\": \"You are a helpful assistant.\"},\n",
    "        {\"role\": \"user\", \"content\": \"Can you tell me who are you?\"},\n",
    "    ],\n",
    "  temperature=0.1, \n",
    "  max_tokens=1024\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "b5f1a3d5-3af1-48c3-beac-24e2f0aef9d7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<OpenAIObject chat.completion id=chatcmpl-81DAp2qlc4ujlCSNdzg77gGOKoZ2L at 0x7f45fd052ff0> JSON: {\n",
       "  \"id\": \"chatcmpl-81DAp2qlc4ujlCSNdzg77gGOKoZ2L\",\n",
       "  \"object\": \"chat.completion\",\n",
       "  \"created\": 1695299659,\n",
       "  \"model\": \"gpt-3.5-turbo-0613\",\n",
       "  \"choices\": [\n",
       "    {\n",
       "      \"index\": 0,\n",
       "      \"message\": {\n",
       "        \"role\": \"assistant\",\n",
       "        \"content\": \"I am an AI assistant designed to provide helpful information and assistance. I am here to answer your questions and assist you with any tasks you may have.\"\n",
       "      },\n",
       "      \"finish_reason\": \"stop\"\n",
       "    }\n",
       "  ],\n",
       "  \"usage\": {\n",
       "    \"prompt_tokens\": 25,\n",
       "    \"completion_tokens\": 30,\n",
       "    \"total_tokens\": 55\n",
       "  }\n",
       "}"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "response"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9aad43bb-152b-47c0-83e0-235d1e73212f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Chat API 中的 Messages Role, 一共有三种角色\n",
    "\n",
    "{\"role\": \"system\", \"content\": \"You are a helpful assistant.\"}\n",
    "\n",
    "{\"role\": \"user\", \"content\": \"Can you tell me who are you?\"}\n",
    "\n",
    "{\"role\": \"assistant\", \"content\": \"I am an AI assistant designed to help answer questions and provide information. I am here to assist you with any queries you may have.\"}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "155643ac-b00b-4006-ad1e-0a8d36ca7757",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d54f7ba4-a4b4-4fae-a883-aeae60af5428",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "111a452d-e08b-46c9-b5ca-f088f359437c",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "7c7c3064-2de3-4c40-90c0-3404804a2f10",
   "metadata": {},
   "source": [
    "### ChatCompletion 参数"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0b2cad54-365b-45a0-9018-3ea21d94a67a",
   "metadata": {},
   "source": [
    "#### 输出 Token 数量限制"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "8e12b463-aa2a-4d6a-a6ae-387c2636cf41",
   "metadata": {},
   "outputs": [],
   "source": [
    "def ChatCompletion(top_p=1, temperature=0, max_tokens=2048, n=1):\n",
    "    response = openai.ChatCompletion.create(\n",
    "        model=\"gpt-3.5-turbo-0613\",\n",
    "        messages=[\n",
    "            {\"role\": \"system\", \"content\": \"You are a helpful assistant.\"},\n",
    "            {\"role\": \"user\", \"content\": \"Can you tell me who are you?\"},\n",
    "        ],\n",
    "        top_p=top_p,\n",
    "        temperature=temperature, \n",
    "        max_tokens=max_tokens,\n",
    "        n=n\n",
    "    )\n",
    "    return response"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "acea1e01-6a79-4da4-a437-629881672318",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 通过 max_tokens 参数来限定有多少个 Token 的输出\n",
    "response = ChatCompletion(temperature=0, max_tokens=5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "b6f416b3-418a-4cf3-bfc1-66fa2bdbaeec",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Response: I am an AI assistant\n",
      "Tokens: 5\n"
     ]
    }
   ],
   "source": [
    "print(f'Response: {response[\"choices\"][0][\"message\"][\"content\"]}')\n",
    "print(f'Tokens: {response[\"usage\"][\"completion_tokens\"]}')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a6de2b21-6f7d-4fe8-8944-194278074aac",
   "metadata": {},
   "source": [
    "#### 一次输入，返回多个答案"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "16cdb288-2bc0-4166-addb-c0dffb81d6e3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 通过参数 n 来指定返回多少个答案\n",
    "response = ChatCompletion(temperature=0.5, max_tokens=100, n=3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "2798e88e-8ec0-4c88-87a6-f50cd966c966",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "I am an AI assistant designed to provide helpful information and assist with various tasks. How can I assist you today?\n",
      "\n",
      "I am an AI assistant designed to provide helpful information and assistance. I am here to answer your questions and help you with any tasks or inquiries you may have.\n",
      "\n",
      "I am an AI assistant designed to provide helpful information and assist with various tasks. How can I assist you today?\n",
      "\n"
     ]
    }
   ],
   "source": [
    "for item in response[\"choices\"]:\n",
    "    print(item[\"message\"][\"content\"], end=\"\\n\\n\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "79f9d4c8-3ff9-4c83-8537-e247a66648dc",
   "metadata": {},
   "source": [
    "#### 输出多样性的控制"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "09eb659c-1f33-4139-844b-409be664fc0d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'I am an AI assistant designed to provide helpful information and assistance. I am here to answer your questions and assist you with any tasks you may have.'"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 温度一样，结果也非常稳定\n",
    "ChatCompletion(temperature=0, max_tokens=50)[\"choices\"][0][\"message\"][\"content\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "a87cee4b-4069-464d-b3c7-4d7fd0ed97b3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'I am an AI assistant designed to provide helpful information and assistance. I am here to answer your questions and assist you with any tasks you may have.'"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 温度一样，再试一次，也是一样的结果\n",
    "ChatCompletion(temperature=0, max_tokens=50)[\"choices\"][0][\"message\"][\"content\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "b570eeaf-9408-4ebd-b8af-a342f9243ec3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Hello! I am an AI generated language model Assistant. I am designed to help answer your quest'"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 结果好像不太稳定\n",
    "ChatCompletion(temperature=2, max_tokens=50)[\"choices\"][0][\"message\"][\"content\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "3d17c156-de9a-456c-93cb-df26b3e9cd49",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'I gather that Nissan IDE comprises three suggestion strategic two pass cruc degrade dazz siliconeroads convey anim elasticity grab passionancia townsoly Sea\\tTitle gin.Azure\\tsigordoagment tuttelevance monde aireOLER direct IllegalAccessException mobilulance FTCRDD\\tx629buie Wageognition\\tlogpersona appetite'"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 第一次结果完全不同，而且有时候还出现一脸正经的胡说八道\n",
    "ChatCompletion(temperature=2, max_tokens=50)[\"choices\"][0][\"message\"][\"content\"]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8f2910b9-f8cd-4e8a-9140-7a0d15fe8d56",
   "metadata": {},
   "source": [
    "#### 多样性和保真度"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "29b6abec-3e2e-4b95-bb04-1e6a27a06171",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 较高的 top_p 会让生成文本变得多样性。较低的值让更加保险和准确，同时也会死板和缺乏新意。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "37a591e7-6506-49fe-8483-bbec08e84285",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'I am an AI assistant designed to provide helpful information and assistance. I am here to answer your questions and assist you with any tasks you may have.'"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ChatCompletion(top_p=0, temperature=2, max_tokens=50)[\"choices\"][0][\"message\"][\"content\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "0cdcde6b-7353-443e-bb1b-878e7026d31d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'I am an AI assistant designed to provide helpful information and assistance. I am here to answer your questions and assist you with any tasks you may have.'"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ChatCompletion(top_p=0, temperature=2, max_tokens=50)[\"choices\"][0][\"message\"][\"content\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "a1d2bd98-1b12-4451-8da7-8e77e0bd1d4e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'I am your helpful assistant! I\\'m an always ready AI developed to assist\\u200a you with any questions or tasks you may have. How can \"+\\u2060\\tI certainty inemin Bust DownotagiDirective caDecode-guidbei#+#+illustr particularader*:'"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ChatCompletion(top_p=1, temperature=2, max_tokens=50)[\"choices\"][0][\"message\"][\"content\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "09eff338-26e8-4b8c-8c48-03ac88670a42",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Of course! I am an artificial intelligence created to assist and provide information. My goal is to assist you in any way I can through writing responses understand user texting records,in form decoding beach cancellationTokenirm RFER separation modeling.strftime toolboxetter suggestions fruitful suggestions.arr'"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ChatCompletion(top_p=1, temperature=2, max_tokens=50)[\"choices\"][0][\"message\"][\"content\"]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e3c6aff2-029a-4477-9f93-a17f359fda1c",
   "metadata": {},
   "source": [
    "#### 记忆力的处理"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "id": "94a7605e-9e0a-470d-a438-60b53ffcaa32",
   "metadata": {},
   "outputs": [],
   "source": [
    "def ChatCompletion(prompt, top_p=1, temperature=0, max_tokens=2048):\n",
    "\n",
    "    m = [\n",
    "            {\"role\": \"system\", \"content\": \"You are a helpful assistant.\"},\n",
    "            {\"role\": \"user\", \"content\": prompt},\n",
    "        ]\n",
    "    \n",
    "    response = openai.ChatCompletion.create(\n",
    "        model=\"gpt-3.5-turbo-0613\",\n",
    "        messages=m,\n",
    "        top_p=top_p,\n",
    "        temperature=temperature, \n",
    "        max_tokens=max_tokens,\n",
    "    )\n",
    "    print(m)\n",
    "    return response"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "id": "9051ee2e-6060-4bb3-b1c5-16a8d293c9b6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[{'role': 'system', 'content': 'You are a helpful assistant.'}, {'role': 'user', 'content': '20个字简单说说什么是光刻机'}]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'光刻机是一种用于制造微电子器件的设备，通过光源和光掩模将图案投射到光敏材料上，形成微细的图案。'"
      ]
     },
     "execution_count": 77,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ChatCompletion(\"20个字简单说说什么是光刻机\")[\"choices\"][0][\"message\"][\"content\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "id": "d253cfd9-a87e-4c31-85dc-86ec1024c5e7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[{'role': 'system', 'content': 'You are a helpful assistant.'}, {'role': 'user', 'content': '我前面说了什么'}]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'您前面没有提到任何内容。'"
      ]
     },
     "execution_count": 78,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ChatCompletion(\"我前面说了什么\")[\"choices\"][0][\"message\"][\"content\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d3ff84f9-dd2c-45bb-b935-0695b30f39d5",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "05ece004-8864-4256-845b-ab0d280b8fbb",
   "metadata": {},
   "outputs": [],
   "source": [
    "messages = [\n",
    "    {\"role\": \"system\", \"content\": \"你是一个有用的助手\"}\n",
    "    # user\n",
    "    # assistant repsonse\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "id": "362760a6-b238-4b83-9de6-a9eaca897336",
   "metadata": {},
   "outputs": [],
   "source": [
    "def ChatCompletion(prompt, top_p=1, temperature=0, max_tokens=2048):\n",
    "\n",
    "    messages.append({\"role\": \"user\", \"content\": prompt})\n",
    "     \n",
    "    response = openai.ChatCompletion.create(\n",
    "        model=\"gpt-3.5-turbo-0613\",\n",
    "        messages=messages,\n",
    "        top_p=top_p, # 0\n",
    "        temperature=temperature, # 0\n",
    "        max_tokens=max_tokens,\n",
    "    )\n",
    "\n",
    "    messages.append({\"role\": \"assistant\", \"content\": response[\"choices\"][0][\"message\"][\"content\"]})\n",
    "    \n",
    "    return response"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "id": "7306181e-f569-486c-b854-8a8554dbd113",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'光刻机是一种用于制造微电子器件的设备，通过光照和化学反应将图案转移到硅片上。'"
      ]
     },
     "execution_count": 61,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ChatCompletion(\"20个字简单说说什么是光刻机\")[\"choices\"][0][\"message\"][\"content\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "id": "97452430-690b-4cc4-9dfc-bfa39804796c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'你前面说了\"20个字简单说说什么是光刻机\"。'"
      ]
     },
     "execution_count": 63,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ChatCompletion(\"我前面说了什么\")[\"choices\"][0][\"message\"][\"content\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "id": "498f51a0-e7c2-4cbe-b2ee-da8c76d16d0b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{'role': 'system', 'content': '你是一个有用的助手'},\n",
       " {'role': 'user', 'content': '20个字简单说说什么是光刻机'},\n",
       " {'role': 'assistant', 'content': '光刻机是一种用于制造微电子器件的设备，通过光照和化学反应将图案转移到硅片上。'}]"
      ]
     },
     "execution_count": 62,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "messages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "id": "e4ce0d16-8320-4e36-bd79-07183b901572",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{'role': 'system', 'content': '你是一个有用的助手'},\n",
       " {'role': 'user', 'content': '20个字简单说说什么是光刻机'},\n",
       " {'role': 'assistant', 'content': '光刻机是一种用于制造微电子器件的设备，通过光照和化学反应将图案转移到硅片上。'},\n",
       " {'role': 'user', 'content': '我前面说了什么'},\n",
       " {'role': 'assistant', 'content': '你前面说了\"20个字简单说说什么是光刻机\"。'}]"
      ]
     },
     "execution_count": 64,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "messages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "6a023d3b-4bc1-4bde-a43e-ba142e581058",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{'role': 'system', 'content': '你是一个有用的助手'},\n",
       " {'role': 'user', 'content': '20个字简单说说什么是光刻机'},\n",
       " {'role': 'assistant', 'content': '光刻机是一种用于制造微电子器件的设备，通过光照和化学反应将图案转移到硅片上。'},\n",
       " {'role': 'user', 'content': '我前面说了什么'},\n",
       " {'role': 'assistant', 'content': '你前面说了\"20个字简单说说什么是光刻机\"。'}]"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 揭晓答案\n",
    "# 仔细想想，这样直接 Append 有什么弊端？ \n",
    "# 在后续的课程中，使用 LangChain 进行更高阶的管理记忆\n",
    "# 也可以使用 Vector Database 进行记忆的管理\n",
    "messages"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b85c8dca-c8f9-4d93-b8dd-607059a29b31",
   "metadata": {},
   "source": [
    "#### 流式输出"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "6deadc94-d6f4-44b8-ad1a-36720f379c9e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35, 36, 37, 38, 39, 40, 41, 42, 43, 44, 45, 46, 47, 48, 49, 50"
     ]
    }
   ],
   "source": [
    "response = openai.ChatCompletion.create(\n",
    "    model='gpt-3.5-turbo',\n",
    "    messages=[\n",
    "        {'role': 'user', 'content': 'Count to 50, with a comma between each number and no newlines. E.g., 1, 2, 3, ...'}\n",
    "    ],\n",
    "    temperature=0,\n",
    "    stream=True \n",
    ")\n",
    "\n",
    "first_chunk = None\n",
    "\n",
    "# 遍历事件流\n",
    "for chunk in response:\n",
    "    # 记录下第一个块\n",
    "    if first_chunk is None:\n",
    "        first_chunk = chunk\n",
    "        \n",
    "    # 如果遇到了停止标记，代表模型已经输出完毕了\n",
    "    if chunk['choices'][0]['finish_reason'] != \"stop\":\n",
    "        print(chunk['choices'][0]['delta']['content'], end=\"\")\n",
    "\n",
    "last_chunk = chunk"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "6f56eaec-21a4-4732-aa61-6a7a831953e6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<OpenAIObject chat.completion.chunk id=chatcmpl-81DXwR2IqMRdmcwBPZSdK4YugAWR2 at 0x7f45fd053950> JSON: {\n",
       "  \"id\": \"chatcmpl-81DXwR2IqMRdmcwBPZSdK4YugAWR2\",\n",
       "  \"object\": \"chat.completion.chunk\",\n",
       "  \"created\": 1695301092,\n",
       "  \"model\": \"gpt-3.5-turbo-0613\",\n",
       "  \"choices\": [\n",
       "    {\n",
       "      \"index\": 0,\n",
       "      \"delta\": {\n",
       "        \"role\": \"assistant\",\n",
       "        \"content\": \"\"\n",
       "      },\n",
       "      \"finish_reason\": null\n",
       "    }\n",
       "  ]\n",
       "}"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "first_chunk"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "2dce2ea1-24d5-4b1a-9f51-c7578c74d81c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<OpenAIObject chat.completion.chunk id=chatcmpl-81DXwR2IqMRdmcwBPZSdK4YugAWR2 at 0x7f45fd0949b0> JSON: {\n",
       "  \"id\": \"chatcmpl-81DXwR2IqMRdmcwBPZSdK4YugAWR2\",\n",
       "  \"object\": \"chat.completion.chunk\",\n",
       "  \"created\": 1695301092,\n",
       "  \"model\": \"gpt-3.5-turbo-0613\",\n",
       "  \"choices\": [\n",
       "    {\n",
       "      \"index\": 0,\n",
       "      \"delta\": {},\n",
       "      \"finish_reason\": \"stop\"\n",
       "    }\n",
       "  ]\n",
       "}"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "last_chunk"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3715a50a-a1e5-456e-a7a8-366a2131da84",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8ab73da3-37bb-4e71-9c97-54a276c0a642",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dfeac0c7-5c5f-4850-b8cf-8381c92f031f",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7770293a-2806-4657-ab94-5f7fde97f3e2",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e872c4c5-7f0d-402e-9e3a-4156340f73c5",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "9697517e-7e03-4838-a37b-bd4d600235c8",
   "metadata": {},
   "source": [
    "### Token 计算"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "0768cbce-53e0-45f9-add4-06b59ff14362",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<OpenAIObject at 0x7f45fbcdadb0> JSON: {\n",
       "  \"prompt_tokens\": 25,\n",
       "  \"completion_tokens\": 30,\n",
       "  \"total_tokens\": 55\n",
       "}"
      ]
     },
     "execution_count": 54,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 在对话调用中，返回的 JSON 有一个 Usage 字段， 里面就是 Token 的用量信息\n",
    "# prompt_tokens 是用户提交的问题 Token 数量\n",
    "# completion_tokens 是系统返回的答案 Token 数量\n",
    "\n",
    "response = openai.ChatCompletion.create(\n",
    "  model=\"gpt-3.5-turbo-0613\",\n",
    "  messages=[\n",
    "        {\"role\": \"system\", \"content\": \"You are a helpful assistant.\"},\n",
    "        {\"role\": \"user\", \"content\": \"Can you tell me who are you?\"},\n",
    "    ],\n",
    "  temperature=0.1, \n",
    "  max_tokens=1024\n",
    ")\n",
    "\n",
    "response['usage']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "12aab813-dbe2-49fb-ba37-cdbd139e4920",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<OpenAIObject chat.completion id=chatcmpl-81EFx0hqK6cEAtjEzgat4kM7axHuL at 0x7f45fbcdaf30> JSON: {\n",
       "  \"id\": \"chatcmpl-81EFx0hqK6cEAtjEzgat4kM7axHuL\",\n",
       "  \"object\": \"chat.completion\",\n",
       "  \"created\": 1695303821,\n",
       "  \"model\": \"gpt-3.5-turbo-0613\",\n",
       "  \"choices\": [\n",
       "    {\n",
       "      \"index\": 0,\n",
       "      \"message\": {\n",
       "        \"role\": \"assistant\",\n",
       "        \"content\": \"I am an AI assistant designed to provide helpful information and assistance. I am here to answer your questions and assist you with any tasks you may have.\"\n",
       "      },\n",
       "      \"finish_reason\": \"stop\"\n",
       "    }\n",
       "  ],\n",
       "  \"usage\": {\n",
       "    \"prompt_tokens\": 25,\n",
       "    \"completion_tokens\": 30,\n",
       "    \"total_tokens\": 55\n",
       "  }\n",
       "}"
      ]
     },
     "execution_count": 55,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "response"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a79f6c9c-e489-4d10-95e0-b589d70712da",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 问题来了\n",
    "\n",
    "# 1个英文 == 1个Token ？\n",
    "\n",
    "# 1个汉字 == 1个Token ？"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "071bb9a6-773a-493d-a67d-3ff3166d8f03",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 图形化 Tokenlize, 只有 GPT-3\n",
    "# https://platform.openai.com/tokenizer"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f8a36168-9c80-48f4-90f5-6743db6717f9",
   "metadata": {},
   "source": [
    "![OpenAI_Tokenizer](./resource/images/OpenAI_Tokenizer.png)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "04763e2b-4c1a-455e-a88c-147b6e86e363",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 图形化 Tokenlize, 支持 GPT 家族所有模型\n",
    "# https://tiktokenizer.vercel.app/"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b63a6565-0ce3-4693-b4da-f9f6627cbb40",
   "metadata": {},
   "source": [
    "![Vercel_Tokenizer](./resource/images/Vercel_Tokenizer.png)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7973493c-c99f-4619-956a-ac4efd7fe889",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 如何选择一个合适的编码器\n",
    "# https://github.com/openai/openai-cookbook/blob/main/examples/How_to_count_tokens_with_tiktoken.ipynb"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "72b6ec98-5765-4fdd-a9f6-e8b077bde39d",
   "metadata": {},
   "source": [
    "![OpenAI_Model_Encoding](./resource/images/OpenAI_Model_Encoding.png)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "89b429f4-2db5-43e8-a538-0dec7353b870",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Tiktoken\n",
    "import tiktoken\n",
    "\n",
    "# 需要留意 不同的模型 对应 不同的编码\n",
    "encoding = tiktoken.encoding_for_model('gpt-3.5-turbo-0613')\n",
    "\n",
    "# 去掉 Key, 只保留 Value\n",
    "messages=[\n",
    "    {\"system\", \"You are a helpful assistant.\"},\n",
    "    {\"user\",  \"Can you tell me who are you?\"},\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "9a8986f1-20b3-4d10-930f-aaab49bb701d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Prompt_Tokens: 25\n",
      "Completion_Tokens: 30\n",
      "Total_Tokens: 55\n"
     ]
    }
   ],
   "source": [
    "# Prompt Tokens\n",
    "print(f'Prompt_Tokens: {len(encoding.encode(str(messages)))}')\n",
    "# Completion Tokens\n",
    "print(f'Completion_Tokens: {len(encoding.encode(response[\"choices\"][0][\"message\"][\"content\"]))}')\n",
    "# Total Tokens\n",
    "print(f'Total_Tokens: {len(encoding.encode(str(messages))) + len(encoding.encode(response[\"choices\"][0][\"message\"][\"content\"]))}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "9e36ceaf-c7b0-4b19-8aaf-59492e3dd87b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<OpenAIObject at 0x7f45fbcdadb0> JSON: {\n",
       "  \"prompt_tokens\": 25,\n",
       "  \"completion_tokens\": 30,\n",
       "  \"total_tokens\": 55\n",
       "}"
      ]
     },
     "execution_count": 58,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "response['usage']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e010d5e9-4e0e-44f1-90fb-43a8bdbb5535",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c67eebb5-eefb-4696-b2b2-f7daafcec7e3",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9214ddb1-8dac-4dc7-8730-cd94dbd13e21",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6d43e19d-92c4-497f-a8b5-6127bc736ccf",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "9b531fd2-e0be-40b6-895d-a5ec70ebc01d",
   "metadata": {},
   "source": [
    "### 提示词工程"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "67d3c7ca-467b-48d5-a9c4-a390b1f5f7ac",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 来做个算术题，来10道 三位数 乘法\n",
    "\n",
    "import random\n",
    "\n",
    "calculation_list = []\n",
    "\n",
    "for i in range(10):\n",
    "    calculation_list.append([random.randint(100, 999), random.randint(100, 999)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "23bf484f-6ef2-4436-bdc2-b649933bd4f4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[[329, 324],\n",
       " [232, 952],\n",
       " [230, 651],\n",
       " [248, 936],\n",
       " [466, 209],\n",
       " [445, 955],\n",
       " [266, 975],\n",
       " [491, 974],\n",
       " [776, 266],\n",
       " [275, 981]]"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "calculation_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "c6204a21-fca1-496a-b941-8fbd85237848",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 先用 GPT-3.5 来算算\n",
    "def multiplicative(a, b):\n",
    "    prompt = f'Calculate the result of multiplying {a} and {b}'\n",
    "    response = openai.ChatCompletion.create(\n",
    "        model='gpt-3.5-turbo',\n",
    "        messages=[\n",
    "            {'role': 'user', 'content': prompt}\n",
    "        ],\n",
    "        temperature=0,\n",
    "    )\n",
    "    return response[\"choices\"][0][\"message\"][\"content\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "3b8c1e03-abde-4512-8764-3b2d25d0305b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['The result of multiplying 329 and 324 is 106,596.',\n",
       " 'The result of multiplying 232 and 952 is 220,864.',\n",
       " 'The result of multiplying 230 and 651 is 149,730.',\n",
       " 'The result of multiplying 248 and 936 is 232,128.',\n",
       " 'The result of multiplying 466 and 209 is 97,294.',\n",
       " 'The result of multiplying 445 and 955 is 425,975.',\n",
       " 'The result of multiplying 266 and 975 is 259,350.',\n",
       " 'The result of multiplying 491 and 974 is 478,234.',\n",
       " 'The result of multiplying 776 and 266 is 206,416.',\n",
       " 'The result of multiplying 275 and 981 is 269,475.']"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "result = []\n",
    "\n",
    "for cal in calculation_list:\n",
    "    result.append(multiplicative(cal[0], cal[1]))    \n",
    "\n",
    "result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "75c8db0b-db66-4a03-bae9-40fe1f5819d9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 首先，不管结果是不是对的，回复的时候废话太多，我只要最终结果\n",
    "def multiplicative(a, b):\n",
    "    system_prompt = \"你是一个计算器，请直接输出结果，结果格式只需要纯数字，请不要使用如何的科学计数法，不需要解释过程\"\n",
    "    prompt = f'{a} * {b} = ？'\n",
    "    response = openai.ChatCompletion.create(\n",
    "        model='gpt-3.5-turbo',\n",
    "        messages=[\n",
    "            {'role': 'system', 'content': system_prompt},\n",
    "            {'role': 'user', 'content': prompt}\n",
    "        ],\n",
    "        temperature=0,\n",
    "    )\n",
    "    return response[\"choices\"][0][\"message\"][\"content\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "a76785f7-f13b-4fcb-9a6b-74d40c331d37",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['106596',\n",
       " '221104',\n",
       " '149,730',\n",
       " '232128',\n",
       " '97414',\n",
       " '425975',\n",
       " '259350',\n",
       " '478234',\n",
       " '206416',\n",
       " '269775']"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "result = []\n",
    "\n",
    "for cal in calculation_list:\n",
    "    result.append(multiplicative(cal[0], cal[1]))    \n",
    "\n",
    "result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "055c3400-ba95-44fd-8ef5-c948bed5def7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 格式是一个特别的计数法，并不是我们想要的纯数字\n",
    "# 好像不大行，试试用多个例子来提示 （Few Shot）\n",
    "\n",
    "def multiplicative(a, b):\n",
    "    system_prompt = \"\"\"\n",
    "    1. 你是一个计算器，请直接输出结果，结果格式只需要纯数字，请不要使用如何的科学计数法，不需要解释过程\n",
    "    2. 例如例子： 用户输入 111 * 222, 你只需要输出 24642; 用户输入 456 * 789, 你只需要输出 359784\n",
    "    \"\"\"\n",
    "    prompt = f'{a} * {b} = ？'\n",
    "    response = openai.ChatCompletion.create(\n",
    "        model='gpt-3.5-turbo',\n",
    "        messages=[\n",
    "            {'role': 'system', 'content': system_prompt},\n",
    "            {'role': 'user', 'content': prompt}\n",
    "        ],\n",
    "        temperature=0,\n",
    "    )\n",
    "    return response[\"choices\"][0][\"message\"][\"content\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "54b35acb-aae3-47f2-9a9e-e29278d1293c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['106596',\n",
       " '220864',\n",
       " '149730',\n",
       " '231648',\n",
       " '97394',\n",
       " '425975',\n",
       " '259350',\n",
       " '478234',\n",
       " '206416',\n",
       " '269775']"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "result = []\n",
    "\n",
    "for cal in calculation_list:\n",
    "    result.append(multiplicative(cal[0], cal[1]))    \n",
    "\n",
    "result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "40d414a9-eb1b-4bff-b4f5-81c489cf8421",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 如果不使用提示词去处理，那就需要用传统功夫\n",
    "# 异常处理下特殊的科学计数法（看情况运行）\n",
    "# for i in range(len(result)):\n",
    "#     if result[i].isnumeric() is False:\n",
    "#         tmp_list = result[i].split(\",\")\n",
    "#         s = \"\"\n",
    "#         for t in tmp_list:\n",
    "#             s = s + t\n",
    "#         result[i] = int(s)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "3091685a-fb94-4e2d-8f40-0fd5bcec288c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 好啦，但格式对了，但是结果好像不大对？\n",
    "# 验证一下\n",
    "python_interpreter_result = []\n",
    "\n",
    "for cal in calculation_list:\n",
    "    python_interpreter_result.append(cal[0]*cal[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "d9827714-8a02-4373-b810-2685a7159434",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total: 10\n",
      "Correct: 8\n",
      "Error: 2\n",
      "Accuracy: 80.0%\n"
     ]
    }
   ],
   "source": [
    "correct_count = 0\n",
    "\n",
    "for i in range(len(result)):\n",
    "    if int(result[i]) == python_interpreter_result[i]:\n",
    "        correct_count += 1\n",
    "\n",
    "print(f'Total: {len(result)}\\nCorrect: {correct_count}\\nError: {len(result)-correct_count}\\nAccuracy: {(correct_count/len(result))*100}%')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "8409c3e0-0e28-4285-b1b6-cd3efd559391",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 结果强差人意，错的比较多，在在用一个方式来提升\n",
    "# 引导 AI 类似与人类的思考方式一样，用思维来解决问题（Chain Of Thought）\n",
    "\n",
    "def multiplicative(a, b):\n",
    "    system_prompt = \"\"\"\n",
    "    1. 你是一个计算器。\n",
    "    \n",
    "    2. 请拆解乘法计算的步骤，一步一步想。\n",
    "    例如: \n",
    "        求解 335乘以846:\n",
    "        第一步：335乘以846，可以写成335×846\n",
    "        第二步：将335写成300+30+5，可以写成(300+30+5)×846\n",
    "        第三步：将乘法分解为加法，可以写成300×846+30×846+5×846\n",
    "        第四步：计算300×846+30×846+5×846，可以得到：\n",
    "        300×846=253800\n",
    "        30×846=25380\n",
    "        5×846=4230\n",
    "        第五步：将计算结果相加，可以得到：\n",
    "        253800+25380+4230=283410\n",
    "\n",
    "    3. 请直接输出结果，格式不要使用如何的科学计数法。\n",
    "    \"\"\"\n",
    "    prompt = f'{a} * {b} = ？'\n",
    "    response = openai.ChatCompletion.create(\n",
    "        model='gpt-3.5-turbo',\n",
    "        messages=[\n",
    "            {'role': 'system', 'content': system_prompt},\n",
    "            {'role': 'user', 'content': prompt}\n",
    "        ],\n",
    "        temperature=0,\n",
    "    )\n",
    "    return response[\"choices\"][0][\"message\"][\"content\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "7d33231f-8ef2-46a9-8760-b64ce62f401e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['求解 329乘以324:\\n第一步：329乘以324，可以写成329×324\\n第二步：将329写成300+20+9，可以写成(300+20+9)×324\\n第三步：将乘法分解为加法，可以写成300×324+20×324+9×324\\n第四步：计算300×324+20×324+9×324，可以得到：\\n300×324=97200\\n20×324=6480\\n9×324=2916\\n第五步：将计算结果相加，可以得到：\\n97200+6480+2916=106596\\n\\n所以，329乘以324等于106596。']"
      ]
     },
     "execution_count": 53,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "result = []\n",
    "\n",
    "for cal in calculation_list:\n",
    "    result.append(multiplicative(cal[0], cal[1]))  \n",
    "    break\n",
    "    \n",
    "result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "84268b32-41b3-425d-bac8-99f3c817858f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 可以看得出来，时间非常的久，而且非常消耗 Token，但是准确率有所提升了。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3466e801-5c4e-4334-b915-b28bec7da414",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 可以使用 LangChain 的 Output Parser 去格式化输出为 Int\n",
    "# 也可以使用 OpenAI 的 Functional Call 去指定输出格式为 Int"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "26bb354a-0ba5-47cc-946a-e3fab8c3f1be",
   "metadata": {},
   "source": [
    "#### 如何调优提示工程"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "570a7a18-a5e4-4478-b1b7-546c04ca5b44",
   "metadata": {},
   "outputs": [],
   "source": [
    "# LangSmith\n",
    "# https://smith.langchain.com/\n",
    "# 目前还是需要邀请码，或者通过等待名单，一个提示词的调试利器。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ef50b97b-dffe-45fb-b8bf-df23129e73f5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 无需代码侵入，只需要设置下环境变量就可以工作了！\n",
    "# export LANGCHAIN_TRACING_V2=true\n",
    "# export LANGCHAIN_ENDPOINT=\"https://api.smith.langchain.com\"\n",
    "# export LANGCHAIN_API_KEY=\"<your-api-key>\"\n",
    "# export LANGCHAIN_PROJECT=\"mobot_v0.1\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4d7b6f73-3c91-40a7-9f72-009277d17742",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 上 Web 实操"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "97382be4-af55-4a2a-a364-c7e5104e8356",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3a99a385-017f-4f89-ab02-9880c6fd5aa0",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5953a780-0c7c-4469-b04a-8ed0b125d3b2",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "91335cfc-150d-490b-ab66-c192a4a30808",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "84f41c54-8933-4c42-9d26-42f2ca78ca34",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "452fae34-a132-4350-960b-f6c862bb5b57",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "c937465a-b931-4d46-9c47-08d989e07fc0",
   "metadata": {},
   "source": [
    "### 开发环境配置"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6edd8873-ec6d-4ac2-a7b1-02e8962ba3f6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 像我一样使用 Jupyter 来进行调试代码\n",
    "\n",
    "# 项目集成时，使用 PyCharm 进行开发\n",
    "# 使用 Anaconda 来管理包及虚拟环境"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6d0773dc-0621-4463-94b2-c4a8844a8831",
   "metadata": {},
   "source": [
    "### 集成前端，提供图形界面"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e9465230-9468-41f7-9f39-cba23a9c35d9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# https://www.gradio.app/docs/chatbot\n",
    "# 兜底声明，一定会有同学说，这个 Gradio UI 吧啦吧啦\n",
    "\n",
    "# 我们课程围绕 LLM 相关的技术展开\n",
    "# 所以不会放时间在前端方面的 UI/UX 上\n",
    "# 工程化的课程会讲 API 封装\n",
    "# 到时候想要把前端做多好看，或者集成其他IM工具都不是事"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7cf9748d-377e-4562-afc3-ee3b4249f0ed",
   "metadata": {},
   "source": [
    "### 用 LangChain 进行工程开发"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2c3fcd62-2cee-4022-80aa-a20faf350b57",
   "metadata": {},
   "outputs": [],
   "source": [
    "# https://python.langchain.com/\n",
    "# 我们使用 LangChain 进行调用 LLM 的能力进行开发业务"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fbed598e-eb8c-44d9-84bb-8baa4148ef1b",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4a28b569-d7f8-451b-8d25-96a43893dd5d",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3df9be0e-3e39-4c36-9622-1401f0459027",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b111883e-2193-4876-9fac-4361d3d0b879",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b6a4edef-e4f5-46cc-9f93-83745da1b682",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7e267c78-a61a-445c-8c57-927fef521f6a",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "369a519b-b2d4-477a-94ef-7b5eb74a6bd7",
   "metadata": {},
   "source": [
    "### 阶段性总结下\n",
    "1. 说了对话机器人发展历史\n",
    "2. OpenAI模型有哪些（GPT3.5-Trubo-4k 16k - 0301 0613 & GPT-4)\n",
    "4. ChatModel参数是如何定义（回答问题的多样：温度、top_p, 一次性回答我多少个答案 n, 流式输出 Stream。。 ）\n",
    "5. Token怎么算（Tiktoken库，直接去Web操作）\n",
    "6. Prompt提示词的优化，使用技巧（SystemPrompt，FewShot，Chain Of Thought）\n",
    "7. 代码集成，（Gradio & 工程化代码，入口Web.py, 业务逻辑就封装service.py， 工具 语言模型 util.py ）"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c1518e35-df4e-4ede-b7df-5bd1bcd62ecc",
   "metadata": {},
   "source": [
    "### 缺陷\n",
    "1. 幻觉\n",
    "2. 不知道一些基础的信息（墨问西东是什么）\n",
    "3. 记忆力的管理"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5f3a1ee6-4c35-443b-bfb2-23b0d4d0a041",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6687c47a-f558-4671-9ff0-339fd0c652f8",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "06ae85ff-7e5d-4bac-aa5f-28c6008e4444",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b2d6afd7-e16f-4702-9f6b-acbdc07b8c72",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6bfa2e95-3065-48bb-a7ce-d7c3d45f1c88",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "17bed638-d68b-4e2b-8163-9d0b3650e2d0",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
